{"episode_reward": [98.5], "loss": [NaN], "mean_absolute_error": [NaN], "nb_steps": [2], "episode": [0], "mean_eps": [NaN], "nb_episode_steps": [2], "mean_q": [NaN], "duration": [13.189375694701742]}